{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 任何运算都可以变成链式图，通过链式图可以进行求导运算\n",
    "\n",
    "# 2.0 当变量为Tensor其涉及运算后所有中间计算变量均为Tensor,例如forward结果\n",
    "\n",
    "# 3.0 当变量为tensor，w.data即适用\n",
    "\n",
    "# 4.0 创建可微分对象，Variable(torch.Tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "x_data=[1.0,2.0,3.0]\n",
    "y_data=[2.0,4.0,6.0]\n",
    "w=Variable(torch.Tensor([1.0]),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict(before training) 4 tensor([4.], grad_fn=<MulBackward>)\n"
     ]
    }
   ],
   "source": [
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred=forward(x)\n",
    "    return(y_pred-y)*(y_pred-y)\n",
    "print(\"predict(before training)\",4,forward(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 定义核心Loss流程，定义Loss，loss.backward()\n",
    "\n",
    "# 6.0 Loss/w存储在w.grad.data中\n",
    "\n",
    "# 7.0 梯度用完要清除，即w.grad.data.zero_()\n",
    "\n",
    "# 8.0 该方法是一个一个优化w，传统向量法是batch方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: 1.0 2.0 tensor([-2.])\n",
      "\tgrad: 2.0 4.0 tensor([-7.8400])\n",
      "\tgrad: 3.0 6.0 tensor([-16.2288])\n",
      "progress: 0 Loss: tensor([7.3159]) w= tensor([1.2607])\n",
      "\tgrad: 1.0 2.0 tensor([-1.4786])\n",
      "\tgrad: 2.0 4.0 tensor([-5.7962])\n",
      "\tgrad: 3.0 6.0 tensor([-11.9981])\n",
      "progress: 1 Loss: tensor([3.9988]) w= tensor([1.4534])\n",
      "\tgrad: 1.0 2.0 tensor([-1.0932])\n",
      "\tgrad: 2.0 4.0 tensor([-4.2852])\n",
      "\tgrad: 3.0 6.0 tensor([-8.8704])\n",
      "progress: 2 Loss: tensor([2.1857]) w= tensor([1.5959])\n",
      "\tgrad: 1.0 2.0 tensor([-0.8082])\n",
      "\tgrad: 2.0 4.0 tensor([-3.1681])\n",
      "\tgrad: 3.0 6.0 tensor([-6.5580])\n",
      "progress: 3 Loss: tensor([1.1946]) w= tensor([1.7012])\n",
      "\tgrad: 1.0 2.0 tensor([-0.5975])\n",
      "\tgrad: 2.0 4.0 tensor([-2.3422])\n",
      "\tgrad: 3.0 6.0 tensor([-4.8484])\n",
      "progress: 4 Loss: tensor([0.6530]) w= tensor([1.7791])\n",
      "\tgrad: 1.0 2.0 tensor([-0.4417])\n",
      "\tgrad: 2.0 4.0 tensor([-1.7316])\n",
      "\tgrad: 3.0 6.0 tensor([-3.5845])\n",
      "progress: 5 Loss: tensor([0.3569]) w= tensor([1.8367])\n",
      "\tgrad: 1.0 2.0 tensor([-0.3266])\n",
      "\tgrad: 2.0 4.0 tensor([-1.2802])\n",
      "\tgrad: 3.0 6.0 tensor([-2.6500])\n",
      "progress: 6 Loss: tensor([0.1951]) w= tensor([1.8793])\n",
      "\tgrad: 1.0 2.0 tensor([-0.2414])\n",
      "\tgrad: 2.0 4.0 tensor([-0.9465])\n",
      "\tgrad: 3.0 6.0 tensor([-1.9592])\n",
      "progress: 7 Loss: tensor([0.1066]) w= tensor([1.9107])\n",
      "\tgrad: 1.0 2.0 tensor([-0.1785])\n",
      "\tgrad: 2.0 4.0 tensor([-0.6997])\n",
      "\tgrad: 3.0 6.0 tensor([-1.4485])\n",
      "progress: 8 Loss: tensor([0.0583]) w= tensor([1.9340])\n",
      "\tgrad: 1.0 2.0 tensor([-0.1320])\n",
      "\tgrad: 2.0 4.0 tensor([-0.5173])\n",
      "\tgrad: 3.0 6.0 tensor([-1.0709])\n",
      "progress: 9 Loss: tensor([0.0319]) w= tensor([1.9512])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0976])\n",
      "\tgrad: 2.0 4.0 tensor([-0.3825])\n",
      "\tgrad: 3.0 6.0 tensor([-0.7917])\n",
      "progress: 10 Loss: tensor([0.0174]) w= tensor([1.9639])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0721])\n",
      "\tgrad: 2.0 4.0 tensor([-0.2828])\n",
      "\tgrad: 3.0 6.0 tensor([-0.5853])\n",
      "progress: 11 Loss: tensor([0.0095]) w= tensor([1.9733])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0533])\n",
      "\tgrad: 2.0 4.0 tensor([-0.2090])\n",
      "\tgrad: 3.0 6.0 tensor([-0.4327])\n",
      "progress: 12 Loss: tensor([0.0052]) w= tensor([1.9803])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0394])\n",
      "\tgrad: 2.0 4.0 tensor([-0.1546])\n",
      "\tgrad: 3.0 6.0 tensor([-0.3199])\n",
      "progress: 13 Loss: tensor([0.0028]) w= tensor([1.9854])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0291])\n",
      "\tgrad: 2.0 4.0 tensor([-0.1143])\n",
      "\tgrad: 3.0 6.0 tensor([-0.2365])\n",
      "progress: 14 Loss: tensor([0.0016]) w= tensor([1.9892])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0215])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0845])\n",
      "\tgrad: 3.0 6.0 tensor([-0.1749])\n",
      "progress: 15 Loss: tensor([0.0008]) w= tensor([1.9920])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0159])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0625])\n",
      "\tgrad: 3.0 6.0 tensor([-0.1293])\n",
      "progress: 16 Loss: tensor([0.0005]) w= tensor([1.9941])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0118])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0462])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0956])\n",
      "progress: 17 Loss: tensor([0.0003]) w= tensor([1.9956])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0087])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0341])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0707])\n",
      "progress: 18 Loss: tensor([0.0001]) w= tensor([1.9968])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0064])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0252])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0522])\n",
      "progress: 19 Loss: tensor([0.0001]) w= tensor([1.9976])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0048])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0187])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0386])\n",
      "progress: 20 Loss: tensor([0.0000]) w= tensor([1.9982])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0035])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0138])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0286])\n",
      "progress: 21 Loss: tensor([0.0000]) w= tensor([1.9987])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0026])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0102])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0211])\n",
      "progress: 22 Loss: tensor([0.0000]) w= tensor([1.9990])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0019])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0075])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0156])\n",
      "progress: 23 Loss: tensor([6.7684e-06]) w= tensor([1.9993])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0014])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0056])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0115])\n",
      "progress: 24 Loss: tensor([3.7001e-06]) w= tensor([1.9995])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0011])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0041])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0085])\n",
      "progress: 25 Loss: tensor([2.0219e-06]) w= tensor([1.9996])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0008])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0030])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0063])\n",
      "progress: 26 Loss: tensor([1.1045e-06]) w= tensor([1.9997])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0006])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0023])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0047])\n",
      "progress: 27 Loss: tensor([6.0411e-07]) w= tensor([1.9998])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0004])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0017])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0034])\n",
      "progress: 28 Loss: tensor([3.2960e-07]) w= tensor([1.9998])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0003])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0012])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0025])\n",
      "progress: 29 Loss: tensor([1.8051e-07]) w= tensor([1.9999])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0002])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0009])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0019])\n",
      "progress: 30 Loss: tensor([9.8744e-08]) w= tensor([1.9999])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0002])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0007])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0014])\n",
      "progress: 31 Loss: tensor([5.4148e-08]) w= tensor([1.9999])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0001])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0005])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0010])\n",
      "progress: 32 Loss: tensor([2.9468e-08]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0001])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0004])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0008])\n",
      "progress: 33 Loss: tensor([1.6088e-08]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0001])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0003])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0006])\n",
      "progress: 34 Loss: tensor([8.7348e-09]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0001])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0002])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0004])\n",
      "progress: 35 Loss: tensor([4.8467e-09]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0001])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0003])\n",
      "progress: 36 Loss: tensor([2.6521e-09]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0001])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0002])\n",
      "progress: 37 Loss: tensor([1.4552e-09]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0001])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0002])\n",
      "progress: 38 Loss: tensor([7.9149e-10]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0001])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0001])\n",
      "progress: 39 Loss: tensor([4.4020e-10]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0001])\n",
      "progress: 40 Loss: tensor([2.3283e-10]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0001])\n",
      "progress: 41 Loss: tensor([1.2028e-10]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 42 Loss: tensor([5.8208e-11]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 43 Loss: tensor([3.8426e-11]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 44 Loss: tensor([2.2737e-11]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 45 Loss: tensor([1.4552e-11]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 46 Loss: tensor([5.6843e-12]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 47 Loss: tensor([3.6380e-12]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 48 Loss: tensor([3.6380e-12]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 49 Loss: tensor([2.0464e-12]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 50 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 51 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 52 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 53 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 54 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 55 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 56 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 57 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 58 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 59 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 60 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 61 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 62 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 63 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 64 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 65 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 66 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 67 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 68 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 69 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 70 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 71 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 72 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 73 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 74 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 75 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 76 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 77 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 78 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 79 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 80 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 81 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 82 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 83 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 84 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 85 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 86 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 87 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 88 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 89 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 90 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 91 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 92 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 93 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 94 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 95 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 96 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 97 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 98 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n",
      "\tgrad: 1.0 2.0 tensor([-0.0000])\n",
      "\tgrad: 2.0 4.0 tensor([-0.0000])\n",
      "\tgrad: 3.0 6.0 tensor([-0.0000])\n",
      "progress: 99 Loss: tensor([9.0949e-13]) w= tensor([2.0000])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for x_val,y_val in zip(x_data,y_data):\n",
    "        l=loss(x_val,y_val)\n",
    "        l.backward()\n",
    "        print(\"\\tgrad:\",x_val,y_val,w.grad.data)\n",
    "        w.data=w.data-0.01*w.grad.data        \n",
    "        w.grad.data.zero_()\n",
    "    print(\"progress:\",epoch,\"Loss:\",l.data,\"w=\",w.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict(after training) 4 hours tensor(8.0000)\n"
     ]
    }
   ],
   "source": [
    "print(\"predict(after training)\",\"4 hours\",forward(4).data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n",
      "2.0 4.0\n",
      "3.0 6.0\n"
     ]
    }
   ],
   "source": [
    "for x_val,y_val in zip(x_data,y_data):\n",
    "    print(x_val,y_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
